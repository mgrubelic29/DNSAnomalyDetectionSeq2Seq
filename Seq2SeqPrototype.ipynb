{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2SeqPrototype.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OzmXC1zAliUf","colab_type":"text"},"source":["The following few segments of code define the two parts of the sequence to sequence (seq2seq) model: the encoder and the decoder. Each of these two parts is a recurrent neural network (RNN), which is a neural network that performs some operation on a sequence of data and uses the output generated by that operation as input for the next step (recurrence). For these RNNs, we use the **Gated Recurrent Unit** (GRU) architecture, as opposed to the more commonly used **Long Short Term Memory** (LSTM) architecture. This is because, despite being a newer architecture, GRU works similarly to LSTM and has been shown to yield similar results while being slightly more efficient computationally. [This paper](https://arxiv.org/pdf/1412.3555v1.pdf) gives a more in-depth overview of the differences between the two architectures.\n","# Encoder\n","In a seq2seq model using an encoder and decoder, the responsibility of the encoder is to encode, or condense, the input sequence into a single vector while retaining the original meaning of that sequence. For each packet in the input sequence, the encoder will produce two things using the embedding layer:\n","\n","\n","\n","1.   A **vector** (called output_vector in the following code)\n","2.   A **hidden state** (called hidden_state in the following code)\n","\n","\n","\n","Following this, the vector and hidden state will be taken as input to do the next step on the next packet in the sequence, and the output vector will be adjusted accordingly and a new hidden state produced. This process is repeated until a final output vector (the **context vector**) is reached, which will be given to the decoder later on. The forward function carries out these tasks in our implementation."]},{"cell_type":"code","metadata":{"id":"BkW1aaqWlirr","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Recurrent neural network for Encoder of the seq2seq model\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies Gated Recurrent Unit (GRU) to input sequence\n","\n","    def forward(self, input_token, hidden_state):\n","        embedded = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = embedded\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31EIQnjDAJqU","colab_type":"text"},"source":["# Decoder\n","\n","The decoder, like the encoder, is a recurrent neural network using GRU architecture. The decoder takes the context vector as its initial hidden state. As before, the forward function carries out the necessary steps, taking an input token and hidden state as input, then producing an output vector and new hidden state. Unlike the encoder, however, the decoder applies the softmax function to the output vector for normalization."]},{"cell_type":"code","metadata":{"id":"U07XVQ3iAFwR","colab_type":"code","colab":{}},"source":["# Recurrent neural network for Decoder of seq2seq model\n","# MIGHT HAVE TO USE ATTN DECODER FROM TUTORIAL\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies GRU\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input_token, hidden_state):\n","        output_vector = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = F.relu(output_vector)\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        output_vector = self.softmax(self.out(output_vector[0]))\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2a3K7y6OpZ8c","colab_type":"code","colab":{}},"source":["# Start and end of connection tokens\n","SOC_token = 0\n","EOC_token = 1\n","\n","# Training function\n","# Criterion = negative log likelihood loss (NLLLoss)\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=320):\n","    encoder_hidden = encoder.init_hidden() # Initialize hidden state of the encoder\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    input_length = input_tensor.size(0) # length of the input sequence\n","    target_length = target_tensor.size(0) # length of the target sequence\n","    #encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    loss = 0\n","\n","# loop through the input tokens w/ encoder and get the final vector/hidden state\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","       # encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOC_token]], device=device)\n","    decoder_hidden = encoder_hidden # Initialize the hidden state of the decoder\n","    # Run the decoder for each element of the target sequence\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      topv, topi = decoder_output.topk(1)\n","      decoder_input = topi.squeeze().detach()\n","      loss = loss + criterion(decoder_output, target_tensor[di]) # Compute the loss\n","      if decoder_input.item() == EOC_token: # break if end of connection token is reached\n","        break\n","\n","    loss.backward()\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HjLI5fifGs8m","colab_type":"code","colab":{}},"source":["import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Helper functions to keep track of the time elapsed and time remaining\n","def as_minutes(sec):\n","    mins = math.floor(sec / 60)\n","    sec = sec - (mins * 60)\n","    return '%dm %ds' % (mins, sec)\n","\n","def time_since(since, percent):\n","    now = time.time()\n","    sec = now-since\n","    es = sec/(percent)\n","    rs = es-sec\n","    return '%sec (- %sec)' % (as_minutes(sec), as_minutes(rs))\n","\n","# Plot loss vs number of iterations\n","#plt.switch_backend('agg')\n","def show_plot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.2) # Put ticks at intervals of 0.2\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0yBSiWAHYKz","colab_type":"code","colab":{}},"source":["# Repeatedly run the train function and print evaluation info as it goes\n","def train_iterations(encoder, decoder, n_iterations, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    # need to make this line work with our data\n","    #training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iterations)]\n","    criterion = nn.NLLLoss()\n","\n","    # Loop to train the model with the specified number of iterations\n","    for iteration in range(1, n_iterations + 1):\n","        training_pair = training_pairs[iteration - 1]\n","        # Tutorial sequences are in pairs with format [input, target]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total = print_loss_total + loss\n","        plot_loss_total = plot_loss_total + loss\n","\n","        # If it has reached the print interval, print progress information\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (time_since(start, iteration / n_iterations), iteration, iteration / n_iterations * 100, print_loss_avg))\n","\n","        # If it has reached the plot interval, add info to the plot_losses array\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    show_plot(plot_losses)"],"execution_count":0,"outputs":[]}]}