{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2SeqPrototype.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FSYnt1NBG7iW","colab_type":"text"},"source":["Read in the sequences csv"]},{"cell_type":"code","metadata":{"id":"5YAwCUpTG5Uo","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import time\n","import os \n","import psutil\n","\n","pd.set_option('display.width', 1000)\n","pd.set_option('display.max_columns', None)\n","\n","# Read the data and filter out unnecessary columns\n","data = pd.read_csv(\"SequenceCSV.csv\", delimiter=',', header=0)\n","data = data.filter(items=['Position','Time','Source IP','Destination IP','Length','Source Port','Destination Port'])\n","print(data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3hkT_TeNgeB","colab_type":"text"},"source":["# Dictionary\n","\n","keep track of \"vocab\""]},{"cell_type":"code","metadata":{"id":"5pZ1qy_YNf5j","colab_type":"code","colab":{}},"source":["class Dict:\n","    def __init__(self, name):\n","        self.name = name\n","        self.token2index = {}\n","        self.token2count = {}\n","        self.index2token = {0: \"SOC\", 1: \"EOC\"}\n","        self.n_tokens = 2  # 2 by default because of SOC/EOC\n","\n","    def add_sequence(self, sequence): # Split the sequence and add the tokens to the dict\n","        for token in sequence.split(' '):\n","            self.add_token(token)\n","\n","    def add_token(self, token): # Add a token to the dict\n","        if token not in self.token2index:\n","            self.token2index[token] = self.n_tokens\n","            self.token2count[token] = 1\n","            self.index2token[self.n_tokens] = token\n","            self.n_tokens += 1\n","        else:\n","            self.token2count[token] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xt1xdUToLDC","colab_type":"text"},"source":["# Data preparation\n","\n","get the data ready and in a format the model can use"]},{"cell_type":"code","metadata":{"id":"PUfwTpZxoNd-","colab_type":"code","colab":{}},"source":["# Use source IPs to start maybe then add other features once its working\n","# Adapt from tutorial code maybe\n","# Space as delimiter between IPs, comma as delimiter between sequences\n","# EXAMPLE [input, target]: [172.195.12.0  195.172.12.0,  192.172.12.0, 172.195.12.0]\n","def read_dicts(sequence_data):\n","  # TRANSFORM SEQUENCES INTO STRINGS AND GET PAIRS FROM DATAFRAME\n","  # PAIRS = INPUT SEQUENCE AND TARGET SEQUENCE\n","\n","def prepare_data(sequence_data): # Read, then populate the dictionaries and generate pairs\n","  input_dict, target_dict, pairs = read_dicts(sequence_data)\n","  for pair in pairs:\n","    input_dict.add_sequence(pair[0])\n","    target_dict.add_sequence(pair[1])\n","  return input_dict, output_dict, pairs\n","\n","# Run the preparation functions\n","input_dict, output_dict, pairs = prepare_data(data)\n","print(random.choice(pairs))\n","\n","# Functions to prepare the data for insertion into the model\n","def indexes_from_sequence(dictionary, sequence):  # Get the indexes for a sequence out of the dictionary\n","    return [dictionary.token2index[token] for token in sequence.split(' ')]\n","\n","def tensor_from_sequence(dictionary, sequence):  # Create a tensor from a sequence using the dictionary\n","    indexes = indexes_from_sequence(dictionary, sequence)\n","    indexes.append(EOC_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensors_from_pair(pair):  # Get an input and target tensor out of a pair\n","    input_tensor = tensor_from_sequence(input_dict, pair[0])\n","    target_tensor = tensor_from_sequence(output_dict, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzmXC1zAliUf","colab_type":"text"},"source":["The following few segments of code define the two parts of the sequence to sequence (seq2seq) model: the encoder and the decoder. Each of these two parts is a recurrent neural network (RNN), which is a neural network that performs some operation on a sequence of data and uses the output generated by that operation as input for the next step (recurrence). For these RNNs, we use the **Gated Recurrent Unit** (GRU) architecture, as opposed to the more commonly used **Long Short Term Memory** (LSTM) architecture. This is because, despite being a newer architecture, GRU works similarly to LSTM and has been shown to yield similar results while being slightly more efficient computationally. [This paper](https://arxiv.org/pdf/1412.3555v1.pdf) gives a more in-depth overview of the differences between the two architectures.\n","# Encoder\n","In a seq2seq model using an encoder and decoder, the responsibility of the encoder is to encode, or condense, the input sequence into a single vector while retaining the original meaning of that sequence. For each packet in the input sequence, the encoder will produce two things using the embedding layer:\n","\n","\n","\n","1.   A **vector** (called output_vector in the following code)\n","2.   A **hidden state** (called hidden_state in the following code)\n","\n","\n","\n","Following this, the vector and hidden state will be taken as input to do the next step on the next packet in the sequence, and the output vector will be adjusted accordingly and a new hidden state produced. This process is repeated until a final output vector (the **context vector**) is reached, which will be given to the decoder later on. The forward function carries out these tasks in our implementation."]},{"cell_type":"code","metadata":{"id":"BkW1aaqWlirr","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Recurrent neural network for Encoder of the seq2seq model\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies Gated Recurrent Unit (GRU) to input sequence\n","\n","    def forward(self, input_token, hidden_state):\n","        embedded = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = embedded\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31EIQnjDAJqU","colab_type":"text"},"source":["# Decoder\n","\n","The decoder, like the encoder, is a recurrent neural network using GRU architecture. The decoder takes the context vector as its initial hidden state. As before, the forward function carries out the necessary steps, taking an input token and hidden state as input, then producing an output vector and new hidden state. Unlike the encoder, however, the decoder applies the softmax function to the output vector for normalization."]},{"cell_type":"code","metadata":{"id":"U07XVQ3iAFwR","colab_type":"code","colab":{}},"source":["# Recurrent neural network for Decoder of seq2seq model\n","# MIGHT HAVE TO USE ATTN DECODER FROM TUTORIAL\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies GRU\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input_token, hidden_state):\n","        output_vector = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = F.relu(output_vector)\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        output_vector = self.softmax(self.out(output_vector[0]))\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0N0Yn9TCPLO-","colab_type":"text"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"HjLI5fifGs8m","colab_type":"code","colab":{}},"source":["import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Helper functions to keep track of the time elapsed and time remaining\n","def as_minutes(sec):\n","    mins = math.floor(sec / 60)\n","    sec = sec - (mins * 60)\n","    return '%dm %ds' % (mins, sec)\n","\n","def time_since(since, percent):\n","    now = time.time()\n","    sec = now-since\n","    es = sec/(percent)\n","    rs = es-sec\n","    return '%sec (- %sec)' % (as_minutes(sec), as_minutes(rs))\n","\n","# Plot loss vs number of iterations\n","# plt.switch_backend('agg')\n","def show_plot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.2) # Put ticks at intervals of 0.2\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"htIAkpwZPG-A","colab_type":"text"},"source":["# Training function"]},{"cell_type":"code","metadata":{"id":"2a3K7y6OpZ8c","colab_type":"code","colab":{}},"source":["# Start and end of connection tokens\n","SOC_token = 0\n","EOC_token = 1\n","\n","# Training function\n","# Criterion = negative log likelihood loss (NLLLoss)\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=320):\n","    encoder_hidden = encoder.init_hidden() # Initialize hidden state of the encoder\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    input_length = input_tensor.size(0) # length of the input sequence\n","    target_length = target_tensor.size(0) # length of the target sequence\n","    #encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    loss = 0\n","\n","# loop through the input tokens w/ encoder and get the final vector/hidden state\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","       # encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOC_token]], device=device)\n","    decoder_hidden = encoder_hidden # Initialize the hidden state of the decoder\n","    # Run the decoder for each element of the target sequence\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","      topv, topi = decoder_output.topk(1)\n","      decoder_input = topi.squeeze().detach()\n","      loss = loss + criterion(decoder_output, target_tensor[di]) # Compute the loss\n","      if decoder_input.item() == EOC_token: # break if end of connection token is reached\n","        break\n","\n","    loss.backward()\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0U1ru16PQsf","colab_type":"text"},"source":["# Training overhead"]},{"cell_type":"code","metadata":{"id":"d0yBSiWAHYKz","colab_type":"code","colab":{}},"source":["# Repeatedly run the train function and print evaluation info as it goes\n","def train_iterations(encoder, decoder, n_iterations, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    # Get the training pairs\n","    training_pairs = [tensors_from_pair(random.choice(pairs)) for i in range(n_iterations)]\n","    criterion = nn.NLLLoss()\n","\n","    # Loop to train the model with the specified number of iterations\n","    for iteration in range(1, n_iterations + 1):\n","        training_pair = training_pairs[iteration - 1]\n","        input_tensor = training_pair[0] # Get an input tensor from the pair\n","        target_tensor = training_pair[1]  # Get a target tensor from the pair\n","        # Train the model on the pairs\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total = print_loss_total + loss\n","        plot_loss_total = plot_loss_total + loss\n","\n","        # If it has reached the print interval, print progress information\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (time_since(start, iteration / n_iterations), iteration, iteration / n_iterations * 100, print_loss_avg))\n","\n","        # If it has reached the plot interval, add info to the plot_losses array\n","        if iteration % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    show_plot(plot_losses)"],"execution_count":0,"outputs":[]}]}