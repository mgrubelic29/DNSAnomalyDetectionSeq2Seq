{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2SeqPrototype.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FSYnt1NBG7iW","colab_type":"text"},"source":["This first bit of code takes care of a few things. First, it gets some of the necessary imports out of the way and sets print options. Then, it reads in the sequence csv file and filters out unnecessary columns, leaving 7 total features:\n","\n","1.   The position of the packet within its sequence. This is used only to parse the csv file back out into sequences.\n","2.   The timestamp of the packet\n","3.   The source IP\n","4.   The destination IP\n","5.   The packet length\n","6.   The source port\n","7.   The destination port\n","\n"]},{"cell_type":"code","metadata":{"id":"5YAwCUpTG5Uo","colab_type":"code","outputId":"89a5f872-bc25-48b4-ffaa-8aeb26d16636","executionInfo":{"status":"ok","timestamp":1584040271170,"user_tz":240,"elapsed":1126,"user":{"displayName":"Chris Saliby","photoUrl":"","userId":"02008656896127910157"}},"colab":{"base_uri":"https://localhost:8080/","height":260}},"source":["import pandas as pd\n","import numpy as np\n","import time\n","import os\n","import random\n","import psutil\n","\n","pd.set_option('display.width', 1000)\n","pd.set_option('display.max_columns', None)\n","\n","# Read the data and filter out unnecessary columns\n","data = pd.read_csv(\"SequenceCSV.csv\", delimiter=',', header=0)\n","data = data.filter(items=['Position','Time','Source IP','Destination IP','Length','Source Port','Destination Port'])\n","print(data)\n","#num_sequences = data.Position.value_counts()[0]\n","#print(num_sequences)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["        Position          Time       Source IP  Destination IP  Length  Source Port  Destination Port\n","0              0     37.294817  172.16.113.105   196.37.75.158      60           79              1024\n","1              1     37.295017   196.37.75.158  172.16.113.105      60         1024                79\n","2              2     37.295563   196.37.75.158  172.16.113.105      60         1024                79\n","3              3     37.307251  172.16.113.105   196.37.75.158      60           79              1024\n","4              4     37.327150  172.16.113.105   196.37.75.158      60           79              1024\n","...          ...           ...             ...             ...     ...          ...               ...\n","465100         3  25253.689350  172.16.112.207   194.27.251.21      60        15901                23\n","465101         0  25253.710980  197.182.91.233   172.16.114.50      60         8803                23\n","465102         1  25253.779420  172.16.112.207   194.27.251.21      60        15901                23\n","465103         2  25253.850980   194.27.251.21   172.16.113.50      60         9959                23\n","465104         3  25253.860990  197.182.91.233   172.16.114.50      60         8803                23\n","\n","[465105 rows x 7 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m3hkT_TeNgeB","colab_type":"text"},"source":["# Dictionary\n","\n","This class is used for data storage and representation, treating each packet as a word might be treated in a language translation application. Each \"token\" (or packet) of a sequence is represented as a one-hot encoded vector, where the index of the packet in the dictionary is used to generate the vector. \n","\n","The token2index dictionary allows the user to access the index of a given packet, while the index2token dictionary allows the inverse. The index2token dictionary also has hard-coded indexes for the start of connection (SOC) and end of connection (EOC) tokens. The token2count dictionary stores the frequency of each token in the overall dataset, which could prove useful to anomaly detection. The dictionary also stores the total number of individual tokens.\n","\n","This class has two functions:\n","\n","1.   add_sequence - splits a sequence into tokens and adds them to the dictionary\n","2.   add_token - adds a token to the Dict by updating the necessary dictionaries\n","\n","This class will be used to build an input dictionary, which deals with the input sequences, and a target dictionary, which deals with the target (or predicted) sequences."]},{"cell_type":"code","metadata":{"id":"5pZ1qy_YNf5j","colab_type":"code","colab":{}},"source":["class Dict:\n","    def __init__(self, name):\n","        self.name = name\n","        self.token2index = {}\n","        self.token2count = {}\n","        self.index2token = {0: \"SOC\", 1: \"EOC\"}\n","        self.n_tokens = 2  # 2 by default because of SOC/EOC\n","\n","    def add_sequence(self, sequence): # Split the sequence and add the tokens to the dict\n","        for token in sequence.split(' '):\n","            self.add_token(token)\n","\n","    def add_token(self, token): # Add a token to the dict\n","        if token not in self.token2index:\n","            self.token2index[token] = self.n_tokens\n","            self.token2count[token] = 1\n","            self.index2token[self.n_tokens] = token\n","            self.n_tokens += 1\n","        else:\n","            self.token2count[token] += 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xt1xdUToLDC","colab_type":"text"},"source":["# Data preparation\n","The purpose of data preparation in this application is to get the data ready to put into a format that the model can read. In the case of an application using pytorch, the data must be stored as tensors. But first, a few default values must be assigned for later on. The SOC and EOC tokens are initialized and given indexes, and a maximum sequence length is defined. For now, the only feature being considered is the source IP, but this will obviously change going forward.\n","\n","### Getting the sequences\n","In order to do this, we need to split each connection into input and target sequences where the input sequence is the first 3 packets of a connection and the target sequence is the rest of the connection. This is handled via the split_sequence function and the sequence_to_string function. First the sequence_to_string function converts the entire connection into a whitespace delimited string, then the split_sequence function separates it into input and target sequences.\n","\n","### Creating the pairs\n","The read_dict function serves as a bit of an overhead for the previous two functions. It will loop through all of the sequences and call the previous functions to split them up into input, target pairs and initialize the input and target Dicts. Finally, the prepare_data function collapses all of the previous functions into a single one, reading the dictionaries and pairs from a call to read_dicts and then filling out the dictionaries by adding the input and target sequences. \n","\n","To make sure that all of this is working correctly, a random [input, target] pair is printed once the data is prepared.\n"]},{"cell_type":"code","metadata":{"id":"PUfwTpZxoNd-","colab_type":"code","outputId":"0cd1a2de-a93e-4563-81ab-a05be865467c","executionInfo":{"status":"ok","timestamp":1584040281343,"user_tz":240,"elapsed":11279,"user":{"displayName":"Chris Saliby","photoUrl":"","userId":"02008656896127910157"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# Start and end of connection tokens\n","SOC_token = 0\n","EOC_token = 1\n","MAX_LENGTH = 320\n","\n","# Split a sequence into input, target\n","def split_sequence(seq_string):\n","  sequence = seq_string.split()\n","  seq1 = \"\"\n","  seq2 = \"\"\n","  for x in range(0, 3): # Input sequence is first 3 packets\n","    seq1 += sequence[x]\n","    seq1 += \" \"\n","\n","  for x in range(3, len(sequence)): # Target sequence is rest of connection\n","    seq2 += sequence[x]\n","    seq2 += \" \" \n","\n","  seq1 = seq1[:-1]\n","  seq2 = seq2[:-1]\n","  return seq1, seq2\n","\n","# Transform a sequence into a string\n","def sequence_to_string(sequence_data, position):\n","  seq_string = sequence_data['Source IP'][position]\n","  position += 1\n","  for pos in range(position, len(sequence_data.index)):\n","    if (sequence_data['Position'][position] == 0):\n","      break\n","    seq_string += \" \"\n","    seq_string += sequence_data['Source IP'][position]\n","    position += 1\n","\n","  seq1, seq2 = split_sequence(seq_string)\n","  return seq1, seq2, position\n","\n","# Use source IPs to start maybe then add other features once its working\n","def read_dicts(dict1, dict2, sequence_data):\n","  num_sequences = sequence_data.Position.value_counts()[0]\n","  position = 0\n","  sequences = []\n","  for x in range(0, num_sequences-1):\n","    seq1, seq2, position = sequence_to_string(sequence_data, position) \n","    sequences.append(seq1)\n","    sequences.append(seq2)\n","\n","  pairs = []\n","  for x in range(0, len(sequences)-1, 2):\n","    pair = [sequences[x], sequences[x+1]]\n","    pairs.append(pair)\n","\n","  input_dict = Dict(dict1)\n","  target_dict = Dict(dict2)\n","  return input_dict, target_dict, pairs\n","\n","def prepare_data(dict1, dict2, sequence_data): # Read, then populate the dictionaries and generate pairs\n","  input_dict, target_dict, pairs = read_dicts(dict1, dict2, sequence_data)\n","  for pair in pairs:\n","    input_dict.add_sequence(pair[0])\n","    target_dict.add_sequence(pair[1])\n","  return input_dict, target_dict, pairs\n","\n","# Run the preparation functions\n","input_dict, target_dict, pairs = prepare_data(\"input\",\"target\",data)\n","print(random.choice(pairs))\n","print(len(pairs))\n","#print(pairs)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["['172.16.112.207 207.25.71.200 172.16.116.44', '207.25.71.200']\n","47355\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Sb_jayIEQMP","colab_type":"text"},"source":["# Make the tensors\n","\n","The final step of data preparation requires us to transform the [input, target] pairs into tensors so that the model can read them. This is done simply with the following three functions:\n","\n","1.   indexes_from_sequence - returns the vectorized format of the tokens in a given sequence\n","2.   tensor_from_sequence - converts the token vectors into tensors\n","3.   tensors_from_pair - calls the previous functions for the input and target sequences of a given pair and returns the resulting tensors"]},{"cell_type":"code","metadata":{"id":"f_MNyrwHETVP","colab_type":"code","colab":{}},"source":["# Functions to prepare the data for insertion into the model\n","def indexes_from_sequence(dictionary, sequence):  # Get the indexes for a sequence out of the dictionary\n","    return [dictionary.token2index[token] for token in sequence.split(' ')]\n","\n","def tensor_from_sequence(dictionary, sequence):  # Create a tensor from a sequence using the dictionary\n","    indexes = indexes_from_sequence(dictionary, sequence)\n","    indexes.append(EOC_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","def tensors_from_pair(pair):  # Get an input and target tensor out of a pair\n","    input_tensor = tensor_from_sequence(input_dict, pair[0])\n","    target_tensor = tensor_from_sequence(target_dict, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzmXC1zAliUf","colab_type":"text"},"source":["The following few segments of code define the two parts of the sequence to sequence (seq2seq) model: the encoder and the decoder. Each of these two parts is a recurrent neural network (RNN), which is a neural network that performs some operation on a sequence of data and uses the output generated by that operation as input for the next step (recurrence). For these RNNs, we use the **Gated Recurrent Unit** (GRU) architecture, as opposed to the more commonly used **Long Short Term Memory** (LSTM) architecture. This is because, despite being a newer architecture, GRU works similarly to LSTM and has been shown to yield similar results while being slightly more efficient computationally. [This paper](https://arxiv.org/pdf/1412.3555v1.pdf) gives a more in-depth overview of the differences between the two architectures.\n","# Encoder\n","In a seq2seq model using an encoder and decoder, the responsibility of the encoder is to encode, or condense, the input sequence into a single vector while retaining the original meaning of that sequence. For each packet in the input sequence, the encoder will produce two things using the embedding layer:\n","\n","\n","\n","1.   A **vector** (called output_vector in the following code)\n","2.   A **hidden state** (called hidden_state in the following code)\n","\n","\n","\n","Following this, the vector and hidden state will be taken as input to do the next step on the next packet in the sequence, and the output vector will be adjusted accordingly and a new hidden state produced. This process is repeated until a final output vector (the **context vector**) is reached, which will be given to the decoder later on. The forward function carries out these tasks in our implementation."]},{"cell_type":"code","metadata":{"id":"BkW1aaqWlirr","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Recurrent neural network for Encoder of the seq2seq model\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies Gated Recurrent Unit (GRU) to input sequence\n","\n","    def forward(self, input_token, hidden_state):\n","        embedded = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = embedded\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"31EIQnjDAJqU","colab_type":"text"},"source":["# Decoder\n","\n","The decoder, like the encoder, is a recurrent neural network using GRU architecture. The decoder takes the context vector as its initial hidden state. As before, the forward function carries out the necessary steps, taking an input token and hidden state as input, then producing an output vector and new hidden state. Unlike the encoder, however, the decoder applies the softmax function to the output vector for normalization."]},{"cell_type":"code","metadata":{"id":"U07XVQ3iAFwR","colab_type":"code","colab":{}},"source":["# Recurrent neural network for Decoder of seq2seq model\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(output_size, hidden_size) # Embedding layer\n","        self.gru = nn.GRU(hidden_size, hidden_size) # Applies GRU\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input_token, hidden_state):\n","        output_vector = self.embedding(input_token).view(1, 1, -1)\n","        output_vector = F.relu(output_vector)\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state)\n","        output_vector = self.softmax(self.out(output_vector[0]))\n","        return output_vector, hidden_state\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"laGAZ1IqyEBY","colab_type":"text"},"source":["# Attn decoder\n","\n","decoder w/ attention mechanism might give better results"]},{"cell_type":"code","metadata":{"id":"3Bet2beXyGjF","colab_type":"code","colab":{}},"source":["class AttnDecoder(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p  # Dropout probability\n","        self.max_length = max_length # Max sequence length\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size) # Embedding layer\n","        self.attention = nn.Linear(self.hidden_size * 2, self.max_length) # Attention layer\n","        self.attention_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p) # Dropout layer\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size) # Apply GRU\n","        self.out = nn.Linear(self.hidden_size, self.output_size) # Out layer\n","\n","    def forward(self, input, hidden_state, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded) # Apply dropout to embedded vector\n","        # Apply attention layer\n","        attention_weights = F.softmax(self.attention(torch.cat((embedded[0], hidden_state[0]), 1)), dim=1)\n","        attention_applied = torch.bmm(attention_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n","        # Combine embedded vector and attn_applied vector to get output\n","        output_vector = torch.cat((embedded[0], attention_applied[0]), 1)\n","        output_vector = self.attention_combine(output_vector).unsqueeze(0)\n","        output_vector = F.relu(output_vector)\n","        output_vector, hidden_state = self.gru(output_vector, hidden_state) # Run GRU layer\n","        output_vector = F.log_softmax(self.out(output_vector[0]), dim=1)\n","\n","        return output_vector, hidden_state, attention_weights\n","\n","    def init_hidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0N0Yn9TCPLO-","colab_type":"text"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"HjLI5fifGs8m","colab_type":"code","colab":{}},"source":["import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Helper functions to keep track of the time elapsed and time remaining\n","def as_minutes(sec):\n","    mins = math.floor(sec / 60)\n","    sec = sec - (mins * 60)\n","    return '%dm %ds' % (mins, sec)\n","\n","def time_since(since, percent):\n","    now = time.time()\n","    sec = now-since\n","    es = sec/(percent)\n","    rs = es-sec\n","    return '%sec (- %sec)' % (as_minutes(sec), as_minutes(rs))\n","\n","# Plot loss vs number of iterations\n","def show_plot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    loc = ticker.MultipleLocator(base=0.5) # Put plot ticks at intervals of 0.5\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"htIAkpwZPG-A","colab_type":"text"},"source":["# Training function"]},{"cell_type":"code","metadata":{"id":"2a3K7y6OpZ8c","colab_type":"code","colab":{}},"source":["teacher_forcing_ratio = 0 # Make 0 if don't want teacher forcing\n","\n","# Training function\n","# Criterion = negative log likelihood loss (NLLLoss)\n","# Lines commented out are for attn decoder\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.init_hidden() # Initialize hidden state of the encoder\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    input_length = input_tensor.size(0) # length of the input sequence\n","    target_length = target_tensor.size(0) # length of the target sequence\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    loss = 0\n","\n","# loop through the input tokens w/ encoder and get the final vector/hidden state\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOC_token]], device=device)\n","    decoder_hidden = encoder_hidden # Initialize the hidden state of the decoder\n","    # Decide whether to use teacher forcing on this run\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Run the decoder for each element of the target sequence\n","    if use_teacher_forcing:\n","      for di in range(target_length):\n","        #decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","        loss = loss + criterion(decoder_output, target_tensor[di])\n","        decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","      for di in range(target_length):\n","        #decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n","        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","        topv, topi = decoder_output.topk(1)\n","        decoder_input = topi.squeeze().detach()\n","        loss = loss + criterion(decoder_output, target_tensor[di]) # Compute the loss\n","        if decoder_input.item() == EOC_token: # break if end of connection token is reached\n","          break\n","\n","    loss.backward()\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0U1ru16PQsf","colab_type":"text"},"source":["# Training overhead"]},{"cell_type":"code","metadata":{"id":"d0yBSiWAHYKz","colab_type":"code","colab":{}},"source":["# Repeatedly run the train function and print evaluation info as it goes\n","def train_iterations(encoder, decoder, n_iterations, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    # Get the training pairs\n","    training_pairs = [tensors_from_pair(random.choice(pairs)) for i in range(n_iterations)]\n","    criterion = nn.NLLLoss()\n","\n","    # Loop to train the model with the specified number of iterations\n","    for iteration in range(1, n_iterations + 1):\n","        training_pair = training_pairs[iteration - 1]\n","        input_tensor = training_pair[0] # Get an input tensor from the pair\n","        target_tensor = training_pair[1]  # Get a target tensor from the pair\n","        # Train the model on the pairs\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total = print_loss_total + loss\n","        plot_loss_total = plot_loss_total + loss\n","\n","        # If it has reached the print interval, print progress information\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (time_since(start, iteration / n_iterations), iteration, iteration / n_iterations * 100, print_loss_avg))\n","\n","        # If it has reached the plot interval, add info to the plot_losses array\n","        if iteration % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    show_plot(plot_losses)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h5L4HWMju1Qc","colab_type":"text"},"source":["# Train the model\n","\n","Define a size for the hidden vector, initialize an encoder and decoder, then run the train_iterations function."]},{"cell_type":"code","metadata":{"id":"olVV6KeZu4fX","colab_type":"code","outputId":"04bffcea-84c3-48b5-c63a-3326b8f4e7e7","executionInfo":{"status":"ok","timestamp":1584040918115,"user_tz":240,"elapsed":648012,"user":{"displayName":"Chris Saliby","photoUrl":"","userId":"02008656896127910157"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["hidden_size = 256\n","encoder1 = Encoder(input_dict.n_tokens, hidden_size).to(device)\n","#decoder1 = Decoder(hidden_size, target_dict.n_tokens).to(device)\n","decoder1 = AttnDecoder(hidden_size, target_dict.n_tokens, dropout_p=0.1).to(device)\n","\n","train_iterations(encoder1, decoder1, n_iterations=40000, print_every=500, learning_rate=0.001)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["0m 9sec (- 12m 35sec) (500 1%) 3.1691\n","0m 16sec (- 10m 24sec) (1000 2%) 2.2994\n","0m 22sec (- 9m 34sec) (1500 3%) 2.0060\n","0m 29sec (- 9m 22sec) (2000 5%) 1.9939\n","0m 36sec (- 9m 9sec) (2500 6%) 1.8116\n","0m 44sec (- 9m 7sec) (3000 7%) 2.0408\n","0m 52sec (- 9m 10sec) (3500 8%) 2.0694\n","1m 0sec (- 9m 3sec) (4000 10%) 1.9642\n","1m 8sec (- 9m 0sec) (4500 11%) 1.9807\n","1m 16sec (- 8m 54sec) (5000 12%) 1.8468\n","1m 24sec (- 8m 51sec) (5500 13%) 1.9318\n","1m 32sec (- 8m 43sec) (6000 15%) 1.8845\n","1m 40sec (- 8m 35sec) (6500 16%) 1.8802\n","1m 47sec (- 8m 24sec) (7000 17%) 1.8175\n","1m 53sec (- 8m 13sec) (7500 18%) 1.8170\n","2m 0sec (- 8m 2sec) (8000 20%) 1.7857\n","2m 7sec (- 7m 52sec) (8500 21%) 1.7858\n","2m 14sec (- 7m 42sec) (9000 22%) 1.7499\n","2m 20sec (- 7m 32sec) (9500 23%) 1.7498\n","2m 27sec (- 7m 23sec) (10000 25%) 1.7043\n","2m 34sec (- 7m 15sec) (10500 26%) 1.6525\n","2m 43sec (- 7m 9sec) (11000 27%) 1.6291\n","2m 51sec (- 7m 3sec) (11500 28%) 1.6468\n","2m 58sec (- 6m 57sec) (12000 30%) 1.7505\n","3m 6sec (- 6m 51sec) (12500 31%) 1.6495\n","3m 14sec (- 6m 44sec) (13000 32%) 1.6487\n","3m 21sec (- 6m 36sec) (13500 33%) 1.5882\n","3m 28sec (- 6m 27sec) (14000 35%) 1.6291\n","3m 35sec (- 6m 19sec) (14500 36%) 1.6010\n","3m 42sec (- 6m 11sec) (15000 37%) 1.6282\n","3m 49sec (- 6m 2sec) (15500 38%) 1.5703\n","3m 56sec (- 5m 54sec) (16000 40%) 1.5665\n","4m 3sec (- 5m 46sec) (16500 41%) 1.5959\n","4m 10sec (- 5m 38sec) (17000 42%) 1.5842\n","4m 18sec (- 5m 31sec) (17500 43%) 1.5317\n","4m 25sec (- 5m 24sec) (18000 45%) 1.5679\n","4m 33sec (- 5m 18sec) (18500 46%) 1.5154\n","4m 42sec (- 5m 12sec) (19000 47%) 1.5217\n","4m 50sec (- 5m 5sec) (19500 48%) 1.5826\n","4m 57sec (- 4m 57sec) (20000 50%) 1.5636\n","5m 6sec (- 4m 51sec) (20500 51%) 1.4903\n","5m 14sec (- 4m 44sec) (21000 52%) 1.5836\n","5m 22sec (- 4m 37sec) (21500 53%) 1.6178\n","5m 29sec (- 4m 29sec) (22000 55%) 1.5628\n","5m 38sec (- 4m 23sec) (22500 56%) 1.5267\n","5m 46sec (- 4m 16sec) (23000 57%) 1.6120\n","5m 54sec (- 4m 8sec) (23500 58%) 1.6045\n","6m 1sec (- 4m 0sec) (24000 60%) 1.6008\n","6m 8sec (- 3m 53sec) (24500 61%) 1.4567\n","6m 16sec (- 3m 45sec) (25000 62%) 1.5837\n","6m 25sec (- 3m 38sec) (25500 63%) 1.5947\n","6m 33sec (- 3m 32sec) (26000 65%) 1.4493\n","6m 43sec (- 3m 25sec) (26500 66%) 1.5106\n","6m 53sec (- 3m 18sec) (27000 67%) 1.5861\n","7m 0sec (- 3m 11sec) (27500 68%) 1.5454\n","7m 7sec (- 3m 3sec) (28000 70%) 1.6862\n","7m 15sec (- 2m 55sec) (28500 71%) 1.5715\n","7m 22sec (- 2m 47sec) (29000 72%) 1.4892\n","7m 30sec (- 2m 40sec) (29500 73%) 1.5298\n","7m 38sec (- 2m 32sec) (30000 75%) 1.4799\n","7m 45sec (- 2m 25sec) (30500 76%) 1.5574\n","7m 53sec (- 2m 17sec) (31000 77%) 1.4665\n","8m 0sec (- 2m 9sec) (31500 78%) 1.4160\n","8m 8sec (- 2m 2sec) (32000 80%) 1.5842\n","8m 16sec (- 1m 54sec) (32500 81%) 1.4952\n","8m 25sec (- 1m 47sec) (33000 82%) 1.5859\n","8m 35sec (- 1m 40sec) (33500 83%) 1.6709\n","8m 45sec (- 1m 32sec) (34000 85%) 1.5909\n","8m 55sec (- 1m 25sec) (34500 86%) 1.4290\n","9m 3sec (- 1m 17sec) (35000 87%) 1.4716\n","9m 11sec (- 1m 9sec) (35500 88%) 1.4583\n","9m 19sec (- 1m 2sec) (36000 90%) 1.5416\n","9m 27sec (- 0m 54sec) (36500 91%) 1.5027\n","9m 35sec (- 0m 46sec) (37000 92%) 1.5533\n","9m 45sec (- 0m 39sec) (37500 93%) 1.5458\n","9m 56sec (- 0m 31sec) (38000 95%) 1.5648\n","10m 6sec (- 0m 23sec) (38500 96%) 1.6606\n","10m 15sec (- 0m 15sec) (39000 97%) 1.5808\n","10m 25sec (- 0m 7sec) (39500 98%) 1.6167\n","10m 34sec (- 0m 0sec) (40000 100%) 1.6113\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBBZ0hmGYPgILOsMwTB/h/wFwLlM3IbiACAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}